---
name: mnemosyne-memory-management
description: Best practices for using Mnemosyne memory system effectively
---

# Mnemosyne Memory Management

**Scope**: Using Mnemosyne's persistent memory system for project-aware semantic memory
**Lines**: ~350
**Last Updated**: 2025-10-27

## When to Use This Skill

Activate this skill when:
- Working with the Mnemosyne memory system
- Storing or retrieving project memories
- Managing memory importance and consolidation
- Understanding namespace strategies (global/project/session)
- Integrating memory into multi-agent workflows
- Optimizing memory usage for context preservation
- Designing memory-backed features

## Core Concepts

### OODA Loop Integration

**Mnemosyne is designed around explicit OODA (Observe-Orient-Decide-Act) loops**:

```
OBSERVE → Recall memories, list context, search by query
ORIENT  → Build memory graph, traverse relationships, load context
DECIDE  → Remember new information, consolidate duplicates
ACT     → Update memories, delete/archive obsolete info
FEEDBACK → Access tracking, importance decay, link strength evolution
```

**Human OODA Loop**:
- Session start loads relevant memories automatically
- Review summaries and memory graph to orient
- Use slash commands to store/search explicitly
- Apply patterns, avoid pitfalls documented in memories
- Access tracking updates importance scores

**Agent OODA Loop**:
- Phase transitions trigger memory queries
- Build context from memory graph automatically
- Auto-store decisions at key checkpoints
- Link new memories to existing knowledge
- Link strength evolves based on co-access patterns

### Memory Namespaces

**Three-tier hierarchy for automatic isolation**:

1. **Global** (`global:*`)
   - Cross-project knowledge
   - General patterns and best practices
   - Tool-specific expertise
   - Reusable workflows

2. **Project** (`project:<repo-name>`)
   - Architecture decisions
   - Project-specific patterns
   - Codebase conventions
   - Team agreements
   - Discovered bugs and fixes

3. **Session** (`session:<timestamp>`)
   - Ephemeral session state
   - Temporary discoveries
   - Work-in-progress decisions
   - Short-lived context

**Namespace Detection**:
- Automatic via git repository detection
- Parses `.claude/CLAUDE.md` for project context
- Falls back to `global` if outside git repo
- Can be overridden explicitly in API calls

### Memory Types

**9 classifications for automatic organization**:

```rust
pub enum MemoryType {
    ArchitectureDecision,  // System design choices
    CodePattern,           // Reusable code structures
    BugFix,               // Resolved issues
    Configuration,        // Setup and settings
    Constraint,           // Limitations and requirements
    Entity,               // Key concepts and objects
    Insight,              // Discovered patterns
    Reference,            // External resources
    Preference,           // Team/project preferences
}
```

**LLM automatically assigns type during enrichment** based on content analysis.

### Importance Scoring

**Scale: 1-10**

| Score | Meaning | Examples | Decay Rate |
|-------|---------|----------|------------|
| 1-3   | Low importance | Temporary notes, trivial details | Fast (50% in 30 days) |
| 4-6   | Medium importance | Code patterns, bug fixes | Medium (50% in 90 days) |
| 7-8   | High importance | Architecture decisions, constraints | Slow (50% in 180 days) |
| 9-10  | Critical | Core principles, team agreements | Very slow (50% in 365 days) |

**Importance evolves over time**:
- Access frequency increases importance
- Time decay decreases importance
- Manual updates override automatic scoring
- Consolidation can boost importance

### Semantic Links

**5 relationship types**:

```rust
pub enum LinkType {
    Extends,       // Builds upon previous memory
    Contradicts,   // Conflicts with previous decision
    Implements,    // Realizes an architectural choice
    References,    // Related information
    Supersedes,    // Replaces outdated memory
}
```

**Link strength (0.0-1.0)**:
- Automatically generated by LLM during enrichment
- Evolves based on co-access patterns
- Used for graph traversal and context building
- Weak links (<0.3) may be pruned over time

## Memory Operations

### Storing Memories

**Via Slash Command**:
```bash
/memory-store <content>
```

**Via MCP Tool**:
```json
{
  "name": "mnemosyne.remember",
  "arguments": {
    "content": "Decided to use PostgreSQL for user database because...",
    "namespace": "project:myapp",
    "importance": 9,
    "context": "Database selection discussion"
  }
}
```

**What happens**:
1. **Namespace Detection**: Determines global/project/session scope
2. **LLM Enrichment**: Claude Haiku generates:
   - Summary (concise overview)
   - Keywords (for search)
   - Tags (categories)
   - Type classification
   - Importance score (if not provided)
3. **Semantic Linking**: Detects relationships with existing memories
4. **Storage**: Persists to SQLite with FTS5 indexing
5. **Returns**: Memory ID for future reference

### Searching Memories

**Via Slash Command**:
```bash
/memory-search <query>
```

**Via MCP Tool**:
```json
{
  "name": "mnemosyne.recall",
  "arguments": {
    "query": "database decisions",
    "namespace": "project:myapp",
    "max_results": 10,
    "min_importance": 5
  }
}
```

**Hybrid search strategy**:
1. **FTS5 keyword search**: Fast text matching
2. **Semantic similarity**: LLM-based relevance
3. **Graph traversal**: Follow strong links
4. **Importance weighting**: Boost high-value memories
5. **Temporal relevance**: Recent memories get slight boost

### Building Context

**Via Slash Command**:
```bash
/memory-context
```

**Via MCP Tool**:
```json
{
  "name": "mnemosyne.context",
  "arguments": {
    "memory_ids": ["uuid-1", "uuid-2"],
    "include_links": true
  }
}
```

**Automatic context loading**:
- Orchestrator loads context at session start
- Optimizer builds context payloads per-agent
- Memory context gets 40% of context budget (Critical)
- Graph traversal finds related memories (2-3 hops)

### Consolidating Memories

**Via Slash Command**:
```bash
/memory-consolidate
```

**Via MCP Tool**:
```json
{
  "name": "mnemosyne.consolidate",
  "arguments": {
    "memory_ids": ["uuid-1", "uuid-2"],
    "namespace": "project:myapp"
  }
}
```

**Consolidation strategies**:
- **Merge**: Combine similar memories into unified version
- **Supersede**: Mark old memory as replaced by newer
- **Strengthen links**: Increase connection strength
- **Boost importance**: Consolidated memories get higher scores

**LLM-guided**: Claude analyzes similarities and conflicts

## Best Practices

### When to Store

**DO store**:
- Architecture decisions and rationale
- Bug root causes and fixes
- Discovered code patterns
- Team agreements and conventions
- Failed approaches and lessons learned
- Key constraints and requirements
- Performance bottlenecks and solutions

**DON'T store**:
- Trivial implementation details
- Temporary session state
- Information already in code/docs
- Obvious or common knowledge
- Incomplete or uncertain information

### Importance Guidelines

**Critical (9-10)**:
- Core architectural principles
- Team-wide agreements
- Breaking constraints
- Critical bug patterns

**High (7-8)**:
- Module-level architecture
- Important patterns
- Significant bugs
- Key configuration

**Medium (4-6)**:
- Code patterns
- Minor bugs
- Local conventions
- Helpful references

**Low (1-3)**:
- Temporary notes
- Session reminders
- Trivial details

### Context Budget Management

**Optimizer allocates context budget**:
- Critical (40%): Essential project context
- Skills (30%): Loaded skills like this one
- Project (20%): Files and code
- General (10%): Miscellaneous

**Memory context is part of Critical (40%)**:
- High-importance memories loaded automatically
- Semantic search finds relevant context
- Graph traversal pulls related information
- Balance memory vs other critical context

### Consolidation Workflow

**Periodic consolidation**:
1. `/memory-list` to browse all memories
2. Identify duplicates or related memories
3. `/memory-consolidate` to merge
4. Review consolidated result
5. Delete or archive superseded memories

**Automatic consolidation triggers**:
- Similar keywords and tags
- Same namespace and type
- High semantic similarity (>0.85)
- Temporal clustering (created within days)

## Integration Patterns

### Multi-Agent Coordination

**Orchestrator**:
- Loads project context from memory at session start
- Stores work plan as memory for future reference
- Tracks agent coordination in session namespace

**Optimizer**:
- Discovers skills and stores discovery in memory
- Builds context payloads using memory graph
- Monitors context budget including memory

**Reviewer**:
- Stores quality gate failures as bug memories
- References past patterns for validation
- Learns from previous review decisions

**Executor**:
- Stores implementation decisions as they're made
- Recalls patterns relevant to current task
- Updates memories when approaches change

### Memory-Backed Context Building

```python
async def build_context_with_memory(task_description: str):
    # 1. Search for relevant memories
    memories = await mnemosyne.recall(
        query=task_description,
        namespace="project:myapp",
        max_results=5,
        min_importance=6
    )

    # 2. Build memory graph
    memory_ids = [m['id'] for m in memories]
    graph = await mnemosyne.graph(
        seed_ids=memory_ids,
        max_hops=2
    )

    # 3. Load full context
    context = await mnemosyne.context(
        memory_ids=graph['all_ids'],
        include_links=True
    )

    # 4. Combine with other context sources
    return {
        "memories": context,
        "files": await load_relevant_files(),
        "skills": await load_relevant_skills()
    }
```

### Checkpoint-Driven Storage

**Store at key decision points**:
- After architecture decisions
- After bug resolution
- After pattern discovery
- Before major refactors
- End of work sessions

**Pattern**:
```python
async def checkpoint_decision(decision: str, rationale: str):
    await mnemosyne.remember(
        content=f"{decision}\n\nRationale: {rationale}",
        namespace="project:myapp",
        importance=8,
        context=get_current_phase()
    )
```

## Common Pitfalls

**Avoiding over-storage**:
- Don't store every small decision
- Avoid duplicating information in code/docs
- Don't store uncertain or incomplete info
- Skip trivial or obvious knowledge

**Avoiding under-storage**:
- Don't assume you'll remember decisions
- Don't skip storing "obvious" architecture choices
- Don't forget to document failed approaches
- Don't neglect to store team agreements

**Namespace confusion**:
- Use `project:` for project-specific memories
- Use `global:` only for cross-project knowledge
- Avoid storing project info in global namespace
- Use `session:` sparingly for truly ephemeral state

**Importance inflation**:
- Don't mark everything as 9-10
- Reserve critical scores for critical decisions
- Let importance decay naturally
- Trust LLM's automatic importance scoring

## Further Reading

- `MCP_SERVER.md`: MCP protocol and tool reference
- `ARCHITECTURE.md`: System architecture and data model
- `README.md`: Quick start and examples
- `/memory-export`: Export memories for backup/review
- `/memory-list`: Browse all memories with filtering
